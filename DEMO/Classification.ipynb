{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTO Feature Engineering with AUTO Machine Learning (Classification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upgrading GML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/muhammad/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting GML\n",
      "  Downloading GML-2.0.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: autofeat in /usr/local/lib/python3.6/dist-packages (from GML) (1.0.0)\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (from GML) (2.3.1)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from GML) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /home/muhammad/.local/lib/python3.6/site-packages (from GML) (0.22.1)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (from GML) (0.90)\n",
      "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (from GML) (0.20.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.6/dist-packages (from autofeat->GML) (1.5.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from autofeat->GML) (0.18.2)\n",
      "Requirement already satisfied: numpy in /home/muhammad/.local/lib/python3.6/site-packages (from autofeat->GML) (1.18.1)\n",
      "Requirement already satisfied: joblib in /home/muhammad/.local/lib/python3.6/site-packages (from autofeat->GML) (0.14.1)\n",
      "Requirement already satisfied: pint in /usr/local/lib/python3.6/dist-packages (from autofeat->GML) (0.11)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from autofeat->GML) (1.0.1)\n",
      "Requirement already satisfied: scipy in /home/muhammad/.local/lib/python3.6/site-packages (from lightgbm->GML) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->GML) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->GML) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from Keras->GML) (3.12)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/muhammad/.local/lib/python3.6/site-packages (from Keras->GML) (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->GML) (1.1.0)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost->GML) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /home/muhammad/.local/lib/python3.6/site-packages (from catboost->GML) (3.1.2)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost->GML) (4.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->autofeat->GML) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /home/muhammad/.local/lib/python3.6/site-packages (from pint->autofeat->GML) (45.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/muhammad/.local/lib/python3.6/site-packages (from pandas>=0.24.0->autofeat->GML) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/muhammad/.local/lib/python3.6/site-packages (from pandas>=0.24.0->autofeat->GML) (2019.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/muhammad/.local/lib/python3.6/site-packages (from matplotlib->catboost->GML) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/muhammad/.local/lib/python3.6/site-packages (from matplotlib->catboost->GML) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/muhammad/.local/lib/python3.6/site-packages (from matplotlib->catboost->GML) (0.10.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost->GML) (1.3.3)\n",
      "Installing collected packages: GML\n",
      "Successfully installed GML-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install GML"
    "!pip3 install category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading iris dataset from sklearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTO Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from GML.Ghalat_Machine_Learning import Ghalat_Machine_Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Ghalat Machine Learning!\n",
      "\n",
      "All models are set to train\n",
      "         Have a tea and leave everything on us ;-)\n"
     ]
    }
   ],
   "source": [
    "gml = Ghalat_Machine_Learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************ \n",
      "Successfully dealt with missing data!\n",
      "\n",
      "X:\n",
      "\n",
      "        0    1    2    3\n",
      "0    5.1  3.5  1.4  0.2\n",
      "1    4.9  3.0  1.4  0.2\n",
      "2    4.7  3.2  1.3  0.2\n",
      "3    4.6  3.1  1.5  0.2\n",
      "4    5.0  3.6  1.4  0.2\n",
      "..   ...  ...  ...  ...\n",
      "145  6.7  3.0  5.2  2.3\n",
      "146  6.3  2.5  5.0  1.9\n",
      "147  6.5  3.0  5.2  2.0\n",
      "148  6.2  3.4  5.4  2.3\n",
      "149  5.9  3.0  5.1  1.8\n",
      "\n",
      "[150 rows x 4 columns] \n",
      "Test Data:\n",
      "\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [] \n",
      "\n",
      " ************************************************************\n",
      "\n",
      " ************************************************************ \n",
      "Successfully encoded categorical data with Target Mean Encoding using Stratified KFolds technique!\n",
      "\n",
      " X:\n",
      "\n",
      "        0    1    2    3\n",
      "0    5.1  3.5  1.4  0.2\n",
      "1    4.9  3.0  1.4  0.2\n",
      "2    4.7  3.2  1.3  0.2\n",
      "3    4.6  3.1  1.5  0.2\n",
      "4    5.0  3.6  1.4  0.2\n",
      "..   ...  ...  ...  ...\n",
      "145  6.7  3.0  5.2  2.3\n",
      "146  6.3  2.5  5.0  1.9\n",
      "147  6.5  3.0  5.2  2.0\n",
      "148  6.2  3.4  5.4  2.3\n",
      "149  5.9  3.0  5.1  1.8\n",
      "\n",
      "[150 rows x 4 columns] \n",
      "\n",
      "Test Data:\n",
      "\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [] \n",
      "\n",
      " ************************************************************\n",
      "\n",
      " ************************************************************ \n",
      " Generating new features !\n",
      " ************************************************************\n",
      "[AutoFeat] The 2 step feature engineering process could generate up to 406 features.\n",
      "[AutoFeat] With 150 data points this new feature matrix would use about 0.00 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 24 transformed features from 4 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 1500 feature combinations from 378 original feature tuples - done.\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 112 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "Pickling array (shape=(96,), dtype=object).\n",
      "Pickling array (shape=(96, 150), dtype=float32).\n",
      "Pickling array (shape=(96,), dtype=object).\n",
      "Pickling array (shape=(150,), dtype=int64).\n",
      "Pickling array (shape=(96,), dtype=object).\n",
      "Pickling array (shape=(96, 150), dtype=float32).\n",
      "Pickling array (shape=(96,), dtype=object).\n",
      "Pickling array (shape=(150,), dtype=int64).\n",
      "Pickling array (shape=(96,), dtype=object).\n",
      "Pickling array (shape=(96, 150), dtype=float32).\n",
      "Pickling array (shape=(96,), dtype=object).\n",
      "Pickling array (shape=(150,), dtype=int64).\n",
      "Pickling array (shape=(96,), dtype=object).\n",
      "Pickling array (shape=(96, 150), dtype=float32).\n",
      "Pickling array (shape=(96,), dtype=object).\n",
      "Pickling array (shape=(150,), dtype=int64).\n",
      "Pickling array (shape=(96,), dtype=object).\n",
      "Pickling array (shape=(96, 150), dtype=float32).\n",
      "Pickling array (shape=(96,), dtype=object).\n",
      "Pickling array (shape=(150,), dtype=int64).\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   10.8s remaining:   16.3s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   11.0s remaining:    7.3s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   15.0s finished\n",
      "[featsel] 10 features after 5 feature selection runs\n",
      "[featsel] 5 features after noise filtering\n",
      "[AutoFeat] Computing 5 new features.\n",
      "[AutoFeat]     5/    5 new features ...done.\n",
      "[AutoFeat] Final dataframe with 9 feature columns (5 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[ 9.89345556 -1.61030408 -8.28315148]\n",
      "1.501077 * x1**2/x2\n",
      "0.400046 * exp(x3)/x2\n",
      "0.360991 * x2**3*x3**2\n",
      "0.346706 * sqrt(x2)/x1\n",
      "0.231019 * sqrt(x2)/x0\n",
      "[AutoFeat] Final score: 0.9733\n",
      "\n",
      " ************************************************************ \n",
      "Successfully generated new features! and selected the best features\n",
      "\n",
      " X:\n",
      "\n",
      "        0    1    2    3  x2**3*x3**2  sqrt(x2)/x0  exp(x3)/x2  sqrt(x2)/x1  \\\n",
      "0    5.1  3.5  1.4  0.2      0.10976     0.232003    0.872431     0.338062   \n",
      "1    4.9  3.0  1.4  0.2      0.10976     0.241473    0.872431     0.394405   \n",
      "2    4.7  3.2  1.3  0.2      0.08788     0.242591    0.939541     0.356305   \n",
      "3    4.6  3.1  1.5  0.2      0.13500     0.266249    0.814269     0.395079   \n",
      "4    5.0  3.6  1.4  0.2      0.10976     0.236643    0.872431     0.328671   \n",
      "..   ...  ...  ...  ...          ...          ...         ...          ...   \n",
      "145  6.7  3.0  5.2  2.3    743.81632     0.340351    1.918112     0.760117   \n",
      "146  6.3  2.5  5.0  1.9    451.25000     0.354931    1.337179     0.894427   \n",
      "147  6.5  3.0  5.2  2.0    562.43200     0.350823    1.420972     0.760117   \n",
      "148  6.2  3.4  5.4  2.3    832.98456     0.374805    1.847071     0.683468   \n",
      "149  5.9  3.0  5.1  1.8    429.78924     0.382766    1.186205     0.752773   \n",
      "\n",
      "     x1**2/x2  \n",
      "0    8.750000  \n",
      "1    6.428571  \n",
      "2    7.876923  \n",
      "3    6.406667  \n",
      "4    9.257143  \n",
      "..        ...  \n",
      "145  1.730769  \n",
      "146  1.250000  \n",
      "147  1.730769  \n",
      "148  2.140741  \n",
      "149  1.764706  \n",
      "\n",
      "[150 rows x 9 columns] \n",
      "\n",
      "Test Data:\n",
      "\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [] \n",
      "\n",
      " ************************************************************\n"
     ]
    }
   ],
   "source": [
    "new_X,y = gml.Auto_Feature_Engineering(X,y,type_of_task='Classification',test_data=None,\n",
    "                                                          splits=6,fill_na_='median',ratio_drop=0.2,\n",
    "                                                          generate_features=True,feateng_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is our new X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>x2**3*x3**2</th>\n",
       "      <th>sqrt(x2)/x0</th>\n",
       "      <th>exp(x3)/x2</th>\n",
       "      <th>sqrt(x2)/x1</th>\n",
       "      <th>x1**2/x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10976</td>\n",
       "      <td>0.232003</td>\n",
       "      <td>0.872431</td>\n",
       "      <td>0.338062</td>\n",
       "      <td>8.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10976</td>\n",
       "      <td>0.241473</td>\n",
       "      <td>0.872431</td>\n",
       "      <td>0.394405</td>\n",
       "      <td>6.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.08788</td>\n",
       "      <td>0.242591</td>\n",
       "      <td>0.939541</td>\n",
       "      <td>0.356305</td>\n",
       "      <td>7.876923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.13500</td>\n",
       "      <td>0.266249</td>\n",
       "      <td>0.814269</td>\n",
       "      <td>0.395079</td>\n",
       "      <td>6.406667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.10976</td>\n",
       "      <td>0.236643</td>\n",
       "      <td>0.872431</td>\n",
       "      <td>0.328671</td>\n",
       "      <td>9.257143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>743.81632</td>\n",
       "      <td>0.340351</td>\n",
       "      <td>1.918112</td>\n",
       "      <td>0.760117</td>\n",
       "      <td>1.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>451.25000</td>\n",
       "      <td>0.354931</td>\n",
       "      <td>1.337179</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>1.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>562.43200</td>\n",
       "      <td>0.350823</td>\n",
       "      <td>1.420972</td>\n",
       "      <td>0.760117</td>\n",
       "      <td>1.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>832.98456</td>\n",
       "      <td>0.374805</td>\n",
       "      <td>1.847071</td>\n",
       "      <td>0.683468</td>\n",
       "      <td>2.140741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>429.78924</td>\n",
       "      <td>0.382766</td>\n",
       "      <td>1.186205</td>\n",
       "      <td>0.752773</td>\n",
       "      <td>1.764706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3  x2**3*x3**2  sqrt(x2)/x0  exp(x3)/x2  sqrt(x2)/x1  \\\n",
       "0    5.1  3.5  1.4  0.2      0.10976     0.232003    0.872431     0.338062   \n",
       "1    4.9  3.0  1.4  0.2      0.10976     0.241473    0.872431     0.394405   \n",
       "2    4.7  3.2  1.3  0.2      0.08788     0.242591    0.939541     0.356305   \n",
       "3    4.6  3.1  1.5  0.2      0.13500     0.266249    0.814269     0.395079   \n",
       "4    5.0  3.6  1.4  0.2      0.10976     0.236643    0.872431     0.328671   \n",
       "..   ...  ...  ...  ...          ...          ...         ...          ...   \n",
       "145  6.7  3.0  5.2  2.3    743.81632     0.340351    1.918112     0.760117   \n",
       "146  6.3  2.5  5.0  1.9    451.25000     0.354931    1.337179     0.894427   \n",
       "147  6.5  3.0  5.2  2.0    562.43200     0.350823    1.420972     0.760117   \n",
       "148  6.2  3.4  5.4  2.3    832.98456     0.374805    1.847071     0.683468   \n",
       "149  5.9  3.0  5.1  1.8    429.78924     0.382766    1.186205     0.752773   \n",
       "\n",
       "     x1**2/x2  \n",
       "0    8.750000  \n",
       "1    6.428571  \n",
       "2    7.876923  \n",
       "3    6.406667  \n",
       "4    9.257143  \n",
       "..        ...  \n",
       "145  1.730769  \n",
       "146  1.250000  \n",
       "147  1.730769  \n",
       "148  2.140741  \n",
       "149  1.764706  \n",
       "\n",
       "[150 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import our own model to make it compete with rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTO Machine Learning (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  LogisticRegressionCV  got validation accuracy of  0.9555555555555556\n",
      "Model  LogisticRegression  got validation accuracy of  0.9555555555555556\n",
      "Model  SVC  got validation accuracy of  0.9555555555555556\n",
      "Model  DecisionTreeClassifier  got validation accuracy of  0.9777777777777777\n",
      "Model  KNeighborsClassifier  got validation accuracy of  0.9555555555555556\n",
      "Model  SGDClassifier  got validation accuracy of  0.9555555555555556\n",
      "Model  RandomForestClassifier  got validation accuracy of  0.9555555555555556\n",
      "Model  AdaBoostClassifier  got validation accuracy of  0.9777777777777777\n",
      "Model  ExtraTreesClassifier  got validation accuracy of  0.9777777777777777\n",
      "Model  XGBClassifier  got validation accuracy of  0.9777777777777777\n",
      "Model  LGBMClassifier  got validation accuracy of  0.9777777777777777\n",
      "Model  CatBoostClassifier  got validation accuracy of  0.9777777777777777\n",
      "Model  GradientBoostingClassifier  got validation accuracy of  0.9777777777777777\n",
      "Model  NaiveBayesGaussian  got validation accuracy of  0.9777777777777777\n",
      "Model  MLPClassifier  got validation accuracy of  0.9555555555555556\n",
      "\n",
      " **************************************** \n",
      "Training Neural Network\n",
      " ****************************************\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Neural Network got validation accuracy of  0.9555555555555556\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               2560      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 43,907\n",
      "Trainable params: 43,907\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      " ************************************************************ \n",
      "Round One Results\n",
      " ************************************************************ \n",
      "                         Model  Val_Accuracy  CV on 5 folds\n",
      "0        LogisticRegressionCV      0.955556       0.980000\n",
      "0          LogisticRegression      0.955556       0.980000\n",
      "0        KNeighborsClassifier      0.955556       0.973333\n",
      "0               MLPClassifier      0.955556       0.973333\n",
      "0          NaiveBayesGaussian      0.977778       0.966667\n",
      "0                         SVC      0.955556       0.966667\n",
      "0               SGDClassifier      0.955556       0.960000\n",
      "0      RandomForestClassifier      0.955556       0.960000\n",
      "0               XGBClassifier      0.977778       0.960000\n",
      "0  GradientBoostingClassifier      0.977778       0.960000\n",
      "0              Neural Network      0.955556       0.955556\n",
      "0      DecisionTreeClassifier      0.977778       0.953333\n",
      "0          AdaBoostClassifier      0.977778       0.953333\n",
      "0        ExtraTreesClassifier      0.977778       0.953333\n",
      "0          CatBoostClassifier      0.977778       0.953333\n",
      "0              LGBMClassifier      0.977778       0.940000 \n",
      " ************************************************************\n",
      "Model  LogisticRegressionCV  got validation accuracy of  0.9555555555555556\n",
      "Model  LogisticRegression  got validation accuracy of  0.9555555555555556\n",
      "Model  KNeighborsClassifier  got validation accuracy of  0.9555555555555556\n",
      "Model  Sequential  got validation accuracy of  0.9333333333333333\n",
      "Model  NaiveBayesGaussian  got validation accuracy of  0.9333333333333333\n",
      "\n",
      " ************************************************************ \n",
      "Round Two Results\n",
      " ************************************************************ \n",
      "                   Model  Val_Accuracy  CV on 5 folds\n",
      "0  LogisticRegressionCV      0.955556       0.980000\n",
      "0    LogisticRegression      0.955556       0.980000\n",
      "0  KNeighborsClassifier      0.955556       0.973333\n",
      "0            Sequential      0.933333       0.966667\n",
      "0    NaiveBayesGaussian      0.933333       0.966667 \n",
      " ************************************************************\n",
      "\n",
      "\n",
      " **************************************** \n",
      "Suggested Models for Stacking\n",
      " **************************************** \n",
      " 0    LogisticRegressionCV\n",
      "0      LogisticRegression\n",
      "0    KNeighborsClassifier\n",
      "Name: Model, dtype: object\n",
      "**************************************** \n",
      " PLEASE NOTE: these results are calculated using  <function accuracy_score at 0x7ff72db50158>\n"
     ]
    }
   ],
   "source": [
    "best_model = gml.GMLClassifier(new_X,y,neural_net='Yes',epochs=100,models=[MLPClassifier()],verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
       "                     max_iter=1000, multi_class='auto', n_jobs=-1, penalty='l2',\n",
       "                     random_state=None, refit=True, scoring=None,\n",
       "                     solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saw? within few lines you just did 70-80% of Data Science :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
