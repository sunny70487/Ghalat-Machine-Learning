{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUTO Feature Engineering with AUTO Machine Learning (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upgrading GML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/home/muhammad/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting GML\n",
      "  Downloading GML-2.0.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: autofeat in /usr/local/lib/python3.6/dist-packages (from GML) (1.0.0)\n",
      "Requirement already satisfied: lightgbm in /usr/local/lib/python3.6/dist-packages (from GML) (2.3.1)\n",
      "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from GML) (2.3.1)\n",
      "Requirement already satisfied: scikit-learn in /home/muhammad/.local/lib/python3.6/site-packages (from GML) (0.22.1)\n",
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (from GML) (0.90)\n",
      "Requirement already satisfied: catboost in /usr/local/lib/python3.6/dist-packages (from GML) (0.20.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.6/dist-packages (from autofeat->GML) (1.5.1)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from autofeat->GML) (0.18.2)\n",
      "Requirement already satisfied: numpy in /home/muhammad/.local/lib/python3.6/site-packages (from autofeat->GML) (1.18.1)\n",
      "Requirement already satisfied: joblib in /home/muhammad/.local/lib/python3.6/site-packages (from autofeat->GML) (0.14.1)\n",
      "Requirement already satisfied: pint in /usr/local/lib/python3.6/dist-packages (from autofeat->GML) (0.11)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.6/dist-packages (from autofeat->GML) (1.0.1)\n",
      "Requirement already satisfied: scipy in /home/muhammad/.local/lib/python3.6/site-packages (from lightgbm->GML) (1.4.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->GML) (2.10.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->GML) (1.0.8)\n",
      "Requirement already satisfied: pyyaml in /usr/lib/python3/dist-packages (from Keras->GML) (3.12)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/muhammad/.local/lib/python3.6/site-packages (from Keras->GML) (1.14.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->GML) (1.1.0)\n",
      "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from catboost->GML) (0.13.2)\n",
      "Requirement already satisfied: matplotlib in /home/muhammad/.local/lib/python3.6/site-packages (from catboost->GML) (3.1.2)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.6/dist-packages (from catboost->GML) (4.5.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.6/dist-packages (from sympy->autofeat->GML) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /home/muhammad/.local/lib/python3.6/site-packages (from pint->autofeat->GML) (45.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /home/muhammad/.local/lib/python3.6/site-packages (from pandas>=0.24.0->autofeat->GML) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/muhammad/.local/lib/python3.6/site-packages (from pandas>=0.24.0->autofeat->GML) (2019.3)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/muhammad/.local/lib/python3.6/site-packages (from matplotlib->catboost->GML) (2.4.6)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/muhammad/.local/lib/python3.6/site-packages (from matplotlib->catboost->GML) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/muhammad/.local/lib/python3.6/site-packages (from matplotlib->catboost->GML) (0.10.0)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly->catboost->GML) (1.3.3)\n",
      "Installing collected packages: GML\n",
      "Successfully installed GML-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install GML"
    "!pip3 install category_encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading iris dataset from sklearn datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTO Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from GML.Ghalat_Machine_Learning import Ghalat_Machine_Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Ghalat Machine Learning!\n",
      "\n",
      "All models are set to train\n",
      "         Have a tea and leave everything on us ;-)\n"
     ]
    }
   ],
   "source": [
    "gml = Ghalat_Machine_Learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************ \n",
      "Successfully dealt with missing data!\n",
      "\n",
      "X:\n",
      "\n",
      "            0     1      2    3      4      5     6       7    8      9    10  \\\n",
      "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
      "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
      "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
      "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
      "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
      "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
      "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
      "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
      "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
      "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
      "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
      "\n",
      "         11    12  \n",
      "0    396.90  4.98  \n",
      "1    396.90  9.14  \n",
      "2    392.83  4.03  \n",
      "3    394.63  2.94  \n",
      "4    396.90  5.33  \n",
      "..      ...   ...  \n",
      "501  391.99  9.67  \n",
      "502  396.90  9.08  \n",
      "503  396.90  5.64  \n",
      "504  393.45  6.48  \n",
      "505  396.90  7.88  \n",
      "\n",
      "[506 rows x 13 columns] \n",
      "Test Data:\n",
      "\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [] \n",
      "\n",
      " ************************************************************\n",
      "\n",
      " ************************************************************ \n",
      "Successfully encoded categorical data with Target Mean Encoding using Stratified KFolds technique!\n",
      "\n",
      " X:\n",
      "\n",
      "            0     1      2    3      4      5     6       7    8      9    10  \\\n",
      "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
      "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
      "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
      "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
      "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
      "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
      "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  21.0   \n",
      "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  21.0   \n",
      "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  21.0   \n",
      "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  21.0   \n",
      "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  21.0   \n",
      "\n",
      "         11    12  \n",
      "0    396.90  4.98  \n",
      "1    396.90  9.14  \n",
      "2    392.83  4.03  \n",
      "3    394.63  2.94  \n",
      "4    396.90  5.33  \n",
      "..      ...   ...  \n",
      "501  391.99  9.67  \n",
      "502  396.90  9.08  \n",
      "503  396.90  5.64  \n",
      "504  393.45  6.48  \n",
      "505  396.90  7.88  \n",
      "\n",
      "[506 rows x 13 columns] \n",
      "\n",
      "Test Data:\n",
      "\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [] \n",
      "\n",
      " ************************************************************\n",
      "\n",
      " ************************************************************ \n",
      " Generating new features !\n",
      " ************************************************************\n",
      "[AutoFeat] The 2 step feature engineering process could generate up to 4186 features.\n",
      "[AutoFeat] With 506 data points this new feature matrix would use about 0.01 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 61 transformed features from 13 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng] Generated 10656 feature combinations from 2701 original feature tuples - done.\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 1255 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "Pickling array (shape=(1035,), dtype=object).\n",
      "Memmapping (shape=(1035, 506), dtype=float32) to new file /dev/shm/joblib_memmapping_folder_6359_429592132/6359-139940609136848-0766108fcf214dde8cc62894576c9ec0.pkl\n",
      "Pickling array (shape=(1035,), dtype=object).\n",
      "Pickling array (shape=(506,), dtype=float64).\n",
      "Pickling array (shape=(1035,), dtype=object).\n",
      "Memmapping (shape=(1035, 506), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6359_429592132/6359-139940609136848-0766108fcf214dde8cc62894576c9ec0.pkl\n",
      "Pickling array (shape=(1035,), dtype=object).\n",
      "Pickling array (shape=(506,), dtype=float64).\n",
      "Pickling array (shape=(1035,), dtype=object).\n",
      "Memmapping (shape=(1035, 506), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6359_429592132/6359-139940609136848-0766108fcf214dde8cc62894576c9ec0.pkl\n",
      "Pickling array (shape=(1035,), dtype=object).\n",
      "Pickling array (shape=(506,), dtype=float64).\n",
      "Pickling array (shape=(1035,), dtype=object).\n",
      "Memmapping (shape=(1035, 506), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6359_429592132/6359-139940609136848-0766108fcf214dde8cc62894576c9ec0.pkl\n",
      "Pickling array (shape=(1035,), dtype=object).\n",
      "Pickling array (shape=(506,), dtype=float64).\n",
      "Pickling array (shape=(1035,), dtype=object).\n",
      "Memmapping (shape=(1035, 506), dtype=float32) to old file /dev/shm/joblib_memmapping_folder_6359_429592132/6359-139940609136848-0766108fcf214dde8cc62894576c9ec0.pkl\n",
      "Pickling array (shape=(1035,), dtype=object).\n",
      "Pickling array (shape=(506,), dtype=float64).\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:   23.9s remaining:   35.9s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   5 | elapsed:   24.3s remaining:   16.2s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   34.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:   34.5s finished\n",
      "[featsel] 24 features after 5 feature selection runs\n",
      "[featsel] 21 features after noise filtering\n",
      "[AutoFeat] Computing 21 new features.\n",
      "[AutoFeat]    21/   21 new features ...done.\n",
      "[AutoFeat] Final dataframe with 34 feature columns (21 new).\n",
      "[AutoFeat] Training final regression model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "91.97485710134602\n",
      "-88.668709 * log(x4)/x7\n",
      "83.429257 * 1/(x2*x7)\n",
      "25.988247 * x5**3/x9\n",
      "-20.893713 * sqrt(x0)*x4**3\n",
      "-7.171226 * exp(x3)*log(x4)\n",
      "-3.569163 * sqrt(x12)*sqrt(x7)\n",
      "0.192868 * x10*log(x12)\n",
      "0.073089 * sqrt(x11)*x5**2\n",
      "0.057033 * x0**3*x3\n",
      "-0.043614 * x10**2*sqrt(x12)\n",
      "0.030205 * x12**3/x6\n",
      "-0.002728 * x6**2/x8\n",
      "-0.000291 * x9**2/x12\n",
      "-0.000111 * x0*exp(x5)\n",
      "-0.000058 * x9**2/x8\n",
      "[AutoFeat] Final score: 0.8863\n",
      "\n",
      " ************************************************************ \n",
      "Successfully generated new features! and selected the best features\n",
      "\n",
      " X:\n",
      "\n",
      "            0     1      2    3      4      5     6       7    8      9  ...  \\\n",
      "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  ...   \n",
      "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  ...   \n",
      "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  ...   \n",
      "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  ...   \n",
      "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  ...   \n",
      "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...  ...   \n",
      "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  ...   \n",
      "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  ...   \n",
      "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  ...   \n",
      "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  ...   \n",
      "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  ...   \n",
      "\n",
      "        x9**2/x12  x8**3*exp(x5)  x10*log(x12)     x12*x6**3     x6**2/x8  \\\n",
      "0    17593.574297     716.945624     24.563077  1.380296e+06  4251.040000   \n",
      "1     6407.439825    4916.939395     39.385355  4.489285e+06  3112.605000   \n",
      "2    14532.009926   10555.913906     24.809041  9.192395e+05  1866.605000   \n",
      "3    16763.265306   29549.936266     20.166259  2.824514e+05   699.213333   \n",
      "4     9246.529081   34297.812856     31.291668  8.486431e+05   979.213333   \n",
      "..            ...            ...           ...           ...          ...   \n",
      "501   7707.238883     729.967491     47.649594  3.190514e+06  4774.810000   \n",
      "502   8208.039648     454.864694     46.327558  4.097056e+06  5882.890000   \n",
      "503  13214.361702    1070.627281     36.327565  4.250140e+06  8281.000000   \n",
      "504  11501.388889     892.476337     39.243131  4.614550e+06  7974.490000   \n",
      "505   9457.994924     415.715029     43.350886  4.156811e+06  6528.640000   \n",
      "\n",
      "       x9**3/x8  exp(x3)*log(x4)  x0**3*x3  sqrt(x11)*x5**2  x0*exp(x5)  \n",
      "0    25934336.0        -0.619897       0.0       861.255610    4.531096  \n",
      "1     7086244.0        -0.757153       0.0       821.383339   16.785202  \n",
      "2     7086244.0        -0.757153       0.0      1023.189014   36.008861  \n",
      "3     3647016.0        -0.780886       0.0       972.843373   35.427090  \n",
      "4     3647016.0        -0.780886       0.0      1017.625811   87.713481  \n",
      "..          ...              ...       ...              ...         ...  \n",
      "501  20346417.0        -0.556870       0.0       860.604565   45.717864  \n",
      "502  20346417.0        -0.556870       0.0       746.179638   20.591725  \n",
      "503  20346417.0        -0.556870       0.0       969.512680   65.051314  \n",
      "504  20346417.0        -0.556870       0.0       915.579078   97.806482  \n",
      "505  20346417.0        -0.556870       0.0       724.394549   19.709050  \n",
      "\n",
      "[506 rows x 34 columns] \n",
      "\n",
      "Test Data:\n",
      "\n",
      " Empty DataFrame\n",
      "Columns: []\n",
      "Index: [] \n",
      "\n",
      " ************************************************************\n"
     ]
    }
   ],
   "source": [
    "new_X,y = gml.Auto_Feature_Engineering(X,y,type_of_task='Regression',test_data=None,\n",
    "                                                          splits=6,fill_na_='median',ratio_drop=0.2,\n",
    "                                                          generate_features=True,feateng_steps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here is our new X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>x9**2/x12</th>\n",
       "      <th>x8**3*exp(x5)</th>\n",
       "      <th>x10*log(x12)</th>\n",
       "      <th>x12*x6**3</th>\n",
       "      <th>x6**2/x8</th>\n",
       "      <th>x9**3/x8</th>\n",
       "      <th>exp(x3)*log(x4)</th>\n",
       "      <th>x0**3*x3</th>\n",
       "      <th>sqrt(x11)*x5**2</th>\n",
       "      <th>x0*exp(x5)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17593.574297</td>\n",
       "      <td>716.945624</td>\n",
       "      <td>24.563077</td>\n",
       "      <td>1.380296e+06</td>\n",
       "      <td>4251.040000</td>\n",
       "      <td>25934336.0</td>\n",
       "      <td>-0.619897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>861.255610</td>\n",
       "      <td>4.531096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6407.439825</td>\n",
       "      <td>4916.939395</td>\n",
       "      <td>39.385355</td>\n",
       "      <td>4.489285e+06</td>\n",
       "      <td>3112.605000</td>\n",
       "      <td>7086244.0</td>\n",
       "      <td>-0.757153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>821.383339</td>\n",
       "      <td>16.785202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14532.009926</td>\n",
       "      <td>10555.913906</td>\n",
       "      <td>24.809041</td>\n",
       "      <td>9.192395e+05</td>\n",
       "      <td>1866.605000</td>\n",
       "      <td>7086244.0</td>\n",
       "      <td>-0.757153</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1023.189014</td>\n",
       "      <td>36.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>16763.265306</td>\n",
       "      <td>29549.936266</td>\n",
       "      <td>20.166259</td>\n",
       "      <td>2.824514e+05</td>\n",
       "      <td>699.213333</td>\n",
       "      <td>3647016.0</td>\n",
       "      <td>-0.780886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>972.843373</td>\n",
       "      <td>35.427090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9246.529081</td>\n",
       "      <td>34297.812856</td>\n",
       "      <td>31.291668</td>\n",
       "      <td>8.486431e+05</td>\n",
       "      <td>979.213333</td>\n",
       "      <td>3647016.0</td>\n",
       "      <td>-0.780886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.625811</td>\n",
       "      <td>87.713481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7707.238883</td>\n",
       "      <td>729.967491</td>\n",
       "      <td>47.649594</td>\n",
       "      <td>3.190514e+06</td>\n",
       "      <td>4774.810000</td>\n",
       "      <td>20346417.0</td>\n",
       "      <td>-0.556870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>860.604565</td>\n",
       "      <td>45.717864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8208.039648</td>\n",
       "      <td>454.864694</td>\n",
       "      <td>46.327558</td>\n",
       "      <td>4.097056e+06</td>\n",
       "      <td>5882.890000</td>\n",
       "      <td>20346417.0</td>\n",
       "      <td>-0.556870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>746.179638</td>\n",
       "      <td>20.591725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13214.361702</td>\n",
       "      <td>1070.627281</td>\n",
       "      <td>36.327565</td>\n",
       "      <td>4.250140e+06</td>\n",
       "      <td>8281.000000</td>\n",
       "      <td>20346417.0</td>\n",
       "      <td>-0.556870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>969.512680</td>\n",
       "      <td>65.051314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11501.388889</td>\n",
       "      <td>892.476337</td>\n",
       "      <td>39.243131</td>\n",
       "      <td>4.614550e+06</td>\n",
       "      <td>7974.490000</td>\n",
       "      <td>20346417.0</td>\n",
       "      <td>-0.556870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>915.579078</td>\n",
       "      <td>97.806482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9457.994924</td>\n",
       "      <td>415.715029</td>\n",
       "      <td>43.350886</td>\n",
       "      <td>4.156811e+06</td>\n",
       "      <td>6528.640000</td>\n",
       "      <td>20346417.0</td>\n",
       "      <td>-0.556870</td>\n",
       "      <td>0.0</td>\n",
       "      <td>724.394549</td>\n",
       "      <td>19.709050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0     1      2    3      4      5     6       7    8      9  ...  \\\n",
       "0    0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  ...   \n",
       "1    0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  ...   \n",
       "2    0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  ...   \n",
       "3    0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  ...   \n",
       "4    0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  ...   \n",
       "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...  ...   \n",
       "501  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  273.0  ...   \n",
       "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0  ...   \n",
       "503  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  273.0  ...   \n",
       "504  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  273.0  ...   \n",
       "505  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  273.0  ...   \n",
       "\n",
       "        x9**2/x12  x8**3*exp(x5)  x10*log(x12)     x12*x6**3     x6**2/x8  \\\n",
       "0    17593.574297     716.945624     24.563077  1.380296e+06  4251.040000   \n",
       "1     6407.439825    4916.939395     39.385355  4.489285e+06  3112.605000   \n",
       "2    14532.009926   10555.913906     24.809041  9.192395e+05  1866.605000   \n",
       "3    16763.265306   29549.936266     20.166259  2.824514e+05   699.213333   \n",
       "4     9246.529081   34297.812856     31.291668  8.486431e+05   979.213333   \n",
       "..            ...            ...           ...           ...          ...   \n",
       "501   7707.238883     729.967491     47.649594  3.190514e+06  4774.810000   \n",
       "502   8208.039648     454.864694     46.327558  4.097056e+06  5882.890000   \n",
       "503  13214.361702    1070.627281     36.327565  4.250140e+06  8281.000000   \n",
       "504  11501.388889     892.476337     39.243131  4.614550e+06  7974.490000   \n",
       "505   9457.994924     415.715029     43.350886  4.156811e+06  6528.640000   \n",
       "\n",
       "       x9**3/x8  exp(x3)*log(x4)  x0**3*x3  sqrt(x11)*x5**2  x0*exp(x5)  \n",
       "0    25934336.0        -0.619897       0.0       861.255610    4.531096  \n",
       "1     7086244.0        -0.757153       0.0       821.383339   16.785202  \n",
       "2     7086244.0        -0.757153       0.0      1023.189014   36.008861  \n",
       "3     3647016.0        -0.780886       0.0       972.843373   35.427090  \n",
       "4     3647016.0        -0.780886       0.0      1017.625811   87.713481  \n",
       "..          ...              ...       ...              ...         ...  \n",
       "501  20346417.0        -0.556870       0.0       860.604565   45.717864  \n",
       "502  20346417.0        -0.556870       0.0       746.179638   20.591725  \n",
       "503  20346417.0        -0.556870       0.0       969.512680   65.051314  \n",
       "504  20346417.0        -0.556870       0.0       915.579078   97.806482  \n",
       "505  20346417.0        -0.556870       0.0       724.394549   19.709050  \n",
       "\n",
       "[506 rows x 34 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets import our own model to make it compete with rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTO Machine Learning (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model  LassoLarsCV  got validation loss of  14.225257562074471\n",
      "Model  LinearRegression  got validation loss of  14.520295604007982\n",
      "Model  SVR  got validation loss of  34.65584364119314\n",
      "Model  DecisionTreeRegressor  got validation loss of  14.14013157894737\n",
      "Model  KNeighborsRegressor  got validation loss of  23.50693157894737\n",
      "Model  SGDRegressor  got validation loss of  12.593967363817244\n",
      "Model  RandomForestRegressor  got validation loss of  12.401642784356744\n",
      "Model  AdaBoostRegressor  got validation loss of  13.040263157894739\n",
      "Model  ExtraTreesRegressor  got validation loss of  11.24135872587723\n",
      "[19:56:26] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Model  XGBRegressor  got validation loss of  11.95118859210784\n",
      "Model  LGBMRegressor  got validation loss of  13.67784305866885\n",
      "Model  CatBoostRegressor  got validation loss of  11.063241998162473\n",
      "Model  GradientBoostingRegressor  got validation loss of  11.550215704542461\n",
      "Model  NaiveBayesianRidge  got validation loss of  12.094469703802234\n",
      "Model  MLPRegressor  got validation accuracy of  30.82411899606129\n",
      "\n",
      " **************************************** \n",
      "Training Neural Network\n",
      " ****************************************\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Neural Network got validation loss of  19.061442554080074\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 256)               8960      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 50,177\n",
      "Trainable params: 50,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      " ************************************************************ \n",
      "Round One Results\n",
      " ************************************************************ \n",
      "                        Model  Validation_Loss\n",
      "0          CatBoostRegressor        11.063242\n",
      "0        ExtraTreesRegressor        11.241359\n",
      "0  GradientBoostingRegressor        11.550216\n",
      "0               XGBRegressor        11.951189\n",
      "0         NaiveBayesianRidge        12.094470\n",
      "0      RandomForestRegressor        12.401643\n",
      "0               SGDRegressor        12.593967\n",
      "0          AdaBoostRegressor        13.040263\n",
      "0              LGBMRegressor        13.677843\n",
      "0      DecisionTreeRegressor        14.140132\n",
      "0                LassoLarsCV        14.225258\n",
      "0           LinearRegression        14.520296\n",
      "0             Neural Network        19.061443\n",
      "0        KNeighborsRegressor        23.506932\n",
      "0               MLPRegressor        30.824119\n",
      "0                        SVR        34.655844 \n",
      " ************************************************************\n",
      "Model  CatBoostRegressor  got validation accuracy of  7.784356341916027\n",
      "Model  ExtraTreesRegressor  got validation accuracy of  7.941904276315813\n",
      "Model  GradientBoostingRegressor  got validation accuracy of  11.70692200002068\n",
      "[19:56:37] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "Model  XGBRegressor  got validation accuracy of  8.932056896724026\n",
      "Model  NaiveBayesianRidge  got validation accuracy of  10.94310486632859\n",
      "\n",
      " ************************************************************ \n",
      "Round Two Results\n",
      " ************************************************************ \n",
      "                        Model  Val_Accuracy\n",
      "0          CatBoostRegressor      7.784356\n",
      "0        ExtraTreesRegressor      7.941904\n",
      "0               XGBRegressor      8.932057\n",
      "0         NaiveBayesianRidge     10.943105\n",
      "0  GradientBoostingRegressor     11.706922 \n",
      " ************************************************************\n",
      "\n",
      "\n",
      " **************************************** \n",
      "Suggested Models for Stacking\n",
      " **************************************** \n",
      " 0      CatBoostRegressor\n",
      "0    ExtraTreesRegressor\n",
      "0           XGBRegressor\n",
      "Name: Model, dtype: object\n",
      "**************************************** \n",
      " PLEASE NOTE: these results are calculated using  <function mean_squared_error at 0x7f46a62a1ea0>\n"
     ]
    }
   ],
   "source": [
    "best_model = gml.GMLRegressor(new_X,y,neural_net='Yes',epochs=100,models=[MLPRegressor()],verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x7f4679c0fef0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saw? within few lines you just did 70-80% of Data Science :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
